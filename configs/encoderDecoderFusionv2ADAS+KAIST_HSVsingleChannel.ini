[DEFAULT]
experiment_name    = fusionv2ADASKAIST_HSVsingleChannel:normalizeBy255_01
generate_new_experiment    = False

[HARDWARE]
device             = gpu
# ["cpu", "gpu"]
seed               = 1
# random seed setting for torch.random operations
n_GPUs             = 1
precision          = full

[DATASET]
train_set_paths    = /media/ferhatcan/common/Image_Datasets/rgbt-ped-detection/data/kaist-rgbt/imageSets/train-all-02.txt,
                    /media/ferhatcan/common/Image_Datasets/Flir/UPDATE 8-19-19_ SB Free Dataset-selected/FLIR_ADAS_1_3/train/
test_set_paths     = /media/ferhatcan/common/Image_Datasets/rgbt-ped-detection/data/kaist-rgbt/imageSets/test-all-01.txt,
                    /media/ferhatcan/common/Image_Datasets/Flir/UPDATE 8-19-19_ SB Free Dataset-selected/FLIR_ADAS_1_3/val/
rgb_range          = 1
# it is used in loss module, if normalized make it 1
batch_size         = 4

scale              = 1
include_noise      = False
noise_sigma        = 1
noise_mean         = 0
include_blur       = False
blur_radius        = 0.2
normalize          = divideBy255
random_flips       = True
channel_number     = 1
# taken image channel
n_colors           = 1
# output image channel this should be handled in dataLoader
hr_shape           = 256, 256
downgrade          = bicubic
validation_size    = 0.1
shuffle_dataset    = True

channel_type       = HSV
which_channel      = 2

[MODEL]
model              = EncoderDecoder
self_ensemble      = False

[ENCODERDECODER]
type = fusionv2
# weightshare, seperate
ir_pretrained_weights = .pre_trained_weights/EncoderDecoderIRv2.pt
eo_pretrained_weights = .pre_trained_weights/EncoderDecoderRGBv3.pt
ir_channel_number = 1
eo_channel_number = 1

output = visible


[OPTIMIZATION]
learning_rate      = 1e-3
decay              = 2-6-10-20
decay_factor_gamma = 0.5
optimizer          = SGD
# options: ['ADAM', 'SGD', 'RMSprop']
momentum           = 0.9
# option for SGD
betas              = 0.9, 0.999
# option for ADAM
epsilon            = 1e-8
# option for ADAM
weight_decay       = 0
gclip              = 0
# gradient clip between [-gclip, gclip], 0 means no clipping

[CHECKPOINT]
load               = False
save               = True
reset              = False
data_test          =
# It is going to be used to test custom inputs and save it to results.

[TRAINING]
training           = True
epoch_num          = 110
loss               = 1*Q+5*QE+5*MSE
# "5*VGG54+0.15*GAN" # weight*loss_type + weight*loss_type --> two different loss function
skip_thr           = 1e8
# skip if a batch have high error
image_range        = 1
# 255
log_every          = 0.1
# batch number
validate_every     = 0.7
log_psnr           = True
log_ssim           = False
# Not implemented yet
pre_train          = load_best
# ["download", "PATH/TO/PRE-TRAINED/MODEL", "load_latest", "load_best"]
only_body          = False
# it should be true if transfer knowdlegde from RGB
fine_tuning        = False
# True if you want to start from pre-trained model (It is redundant)
freeze_initial_layers = False
# It freezes desired first layers (developing continues)
chop               = False
# Not used now but it requires for big images
save_models        = False

[TESTING]
benchmarks         = MSE+L1+QE+Q
test_only          = False
log_test_result    = True
test_single        = False
test_psnr          = True
test_ssim          = False
test_visualize     = True
test_image_save    = False

